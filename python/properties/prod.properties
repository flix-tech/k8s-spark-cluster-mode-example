spark.executor.instances=5
spark.kubernetes.namespace=data-flux
spark.kubernetes.allocation.batch.size=5
#Time to wait between each round of executor pod allocation. Specifying values less than 1 second may lead to excessive CPU usage on the spark driver.
spark.kubernetes.allocation.batch.delay=1s
#Service account that is used when running the driver pod. The driver pod uses this service account when requesting executor pods from the API server. Note that this cannot be specified alongside a CA cert file, client key file, client cert file, and/or OAuth token. In client mode, use spark.kubernetes.authenticate.serviceAccountName instead.
spark.kubernetes.authenticate.driver.serviceAccountName=spark
spark.kubernetes.executor.lostCheck.maxAttempts=10	
#In cluster mode, whether to wait for the application to finish before exiting the launcher process. When changed to false, the launcher has a "fire-and-forget" behavior when launching the Spark job.
spark.kubernetes.submission.waitAppCompletion=false	
#Interval between reports of the current Spark job status in cluster mode.
spark.kubernetes.report.interval=1s	
spark.kubernetes.pyspark.pythonVersion=3

#kubernetes resource managements
spark.kubernetes.driver.request.cores=10m
spark.kubernetes.executor.request.cores=50m
spark.driver.memory=500m
spark.executor.memory=500m
spark.kubernetes.memoryOverheadFactor=0.1

#kubernetes driver/executor pod templates
spark.kubernetes.driver.podTemplateFile=./python/pod-templates/driver-pod-template.yaml
spark.kubernetes.executor.podTemplateFile=./python/pod-templates/executor-pod-template.yaml
#datadog monitoring integration
spark.sql.streaming.metricsEnabled=true