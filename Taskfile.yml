# https://taskfile.dev

version: '2'
env:
  PROJECT_NAME: k8s-spark-example
#env: envs to be set on runtime
  #KUBE_CONTEXT: minikube
  #DOCKER_REGISTRY: ci-dump-dcr.mfb.io
  #NAMESPACE: default

tasks:

  run.local:
    deps: [set.k8s.context]
    cmds:
      - >
        eval $(minikube docker-env);
        source ./local.env;
        docker pull gcr.io/spark-operator/spark-py:v2.4.4;
        task docker.build;
        task k8s.deploy.rolebinding;
        task spark.helm.deploy

  start.minikube:
    cmds:
      - if minikube status | grep Running; then echo "minikube running..."; else echo "starting minikube"; minikube start; fi

  default:
    cmds:
      - echo 'executed on {{if ne .KUBE_CONTEXT "minikube"}}remote{{else}}local{{end}}'
    silent: true

  docker.build:
    deps: [set.k8s.context]
    cmds: 
      - docker build -t $DOCKER_REGISTRY/data/spark-py-example:latest .
      - '{{if ne .KUBE_CONTEXT "minikube"}}docker push $DOCKER_REGISTRY/data/spark-py-example:latest{{end}}'

  #private task, this task is only been executed inside spark driver
  spark.deploy:
    cmds:
      - >
        /opt/spark/bin/spark-submit
        --master k8s://https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT
        --deploy-mode client 
        --name $DEPLOYMENT_NAME
        --conf spark.kubernetes.driver.pod.name=$MY_POD_NAME
        --conf spark.driver.host=$DRIVER_HOSTNAME
        --conf spark.driver.port=35861
        --conf spark.kubernetes.container.image=$CONTAINER_IMAGE
        --properties-file /opt/spark.properties
        local:///opt/example/python/pi.py

  spark.helm.deploy:
    deps: [set.k8s.context]
    cmds:
      - >
        {{range $service := .SERVICES | trim | splitLines -}}
          helm upgrade {{$service}} $HELM_CHART_NAME-helm \
            --namespace $NAMESPACE \
            --install \
            --set-string spark_driver.image.repository=$DOCKER_REGISTRY/data/spark-py-example \
            --set-string spark_driver.image.tag=latest \
            --force \
            --values ./helm-values/{{$service}}-helm-values/values-$ENV.yaml;
        {{end}}
    vars:
      SERVICES: |
        k8s-spark-example

  spark.helm.undeploy:
    deps: [set.k8s.context]
    cmds:
      - >
        {{range $service := .SERVICES | trim | splitLines -}}
          helm uninstall --namespace $NAMESPACE {{$service}}
        {{end}}
    vars:
      SERVICES: |
        k8s-spark-example

  set.k8s.context:
    cmds:
      - kubectl config set-context $KUBE_CONTEXT --namespace=$NAMESPACE
      - kubectl config use-context $KUBE_CONTEXT --namespace=$NAMESPACE

  k8s.deploy.rolebinding:
    deps: [set.k8s.context]
    cmds:
      - kubectl -n $NAMESPACE apply -f k8s/rolebinding.yaml # https://git.flix.tech/data/flux/web-tracking/k8s-spark/raw/master/k8s/rolebinding.yaml
